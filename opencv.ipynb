{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(100000)\n",
    "b = np.random.rand(100000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Vectorized version:\"+ str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用窗口大小不同（5，7，9）的核函数来做中值滤波\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"\")\n",
    "\n",
    "e1 = cv2.getTickCount()\n",
    "for i in range(5,49,2):\n",
    "    img1 = cv2.medianBlur(img1,i)\n",
    "e2 = cv2.getTickCount()\n",
    "t = (e2-e1)/cv2.getTickFrequency()\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV blur归一化滤波、GaussianBlur高斯滤波、medianBlur中值滤波\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\" \")\n",
    "cv2.imshow('org',img)\n",
    "kernelsizes = [(3,3),(9,9),(15,15)]\n",
    "\n",
    "for kernel in kernelsizes:\n",
    "    blur = cv2.blur(img,kernel)\n",
    "    cv2.imshow('Average:'+str(kernel),blur)\n",
    "\n",
    "for kernel in kernelsizes:\n",
    "    gaussian = cv2.GaussianBlur(img,kernel,0)\n",
    "    cv2.imshow('GaussianBlur:'+str(kernel),gaussian)\n",
    "\n",
    "for kernel in (3,9,15):\n",
    "    median = cv2.medianBlur(img,kernel)\n",
    "    cv2.imshow('MedianBlur:'+str(kernel),median)\n",
    "\n",
    "params = [(90,50,10),(50,90,10),(10,90,50)]\n",
    "for p1,p2,p3 in params:\n",
    "    bilateral = cv2.bilateralFilter(img,p1,p2,p3)\n",
    "    cv2.imshow('bilateral'+str((p1,p2,p3)),bilateral)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img = cv2.imread(\"\")\n",
    "result = cv2.blur(img,(10,10))\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"result\",result)\n",
    "cv2.waitKey()\n",
    "cv2.destoryAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "def rgb2gray(img):\n",
    "    imageInfo=img.shape\n",
    "    h=imageInfo[0]\n",
    "    w=imageInfo[1]\n",
    "    img1=np.zeros((h,w),np.uint8)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            img1[i,j]=0.144*img[i,j,0]+0.587*img[i,j,1]+0.299*img[i,j,2]\n",
    "    return img1\n",
    "\n",
    "def noise(img,snr):\n",
    "    imageInfo=img.shape\n",
    "    h=imageInfo[0]\n",
    "    w=imageInfo[1]\n",
    "    img1=img.copy()\n",
    "    sp=h*w # 计算五项像素点个数\n",
    "    NP=int(sp*(1-snr)) # 计算图像椒盐噪声点个数\n",
    "    for i in range(NP):\n",
    "        randx=np.random.randint(1,h-1) # 生成一个1至h-1之间的随机整数\n",
    "        randy=np.random.randint(1,w-1) # 生成一个1至w-1之间的随机整数\n",
    "        if np.random.random()<=0.5:\n",
    "            img1[randx,randy]=0\n",
    "        else:\n",
    "            img1[randx,randy]=255\n",
    "    return img1\n",
    "\n",
    "image = cv.imread(\"\")\n",
    "grayimage=rgb2gray(image)\n",
    "noiseimage=noise(grayimage,0.8)\n",
    "result1 = cv.medianBlur(noiseimage,3)\n",
    "result2 = cv.medianBlur(noiseimage,7)\n",
    "cv.imshow(\"grayimge\",grayimage)\n",
    "cv.imshow(\"noiseimage\",noiseimage)\n",
    "cv.imshow(\"result1\",result1)\n",
    "cv.imshow(\"result2\",result2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 全局阈值\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "img1=np.float32(img)\n",
    "kernel=np.ones((5,5),np.float32)/25\n",
    "\n",
    "dst = cv2.filter2D(img1,-1,kernel)\n",
    "plt.subplot(1,2,1),plt.imshow(img1,'gray')\n",
    "plt.subplot(1,2,2),plt.imshow(dst,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_org = cv2.imread(\"\")\n",
    "img = cv2.cvtColor(img_org,cv2.COLOR_BGR2GRAY)\n",
    "img_org = img_org[:,:,::-1]\n",
    "\"\"\"\n",
    "threshhold(图片，阈值，最大值，类型)\n",
    "五个常用的阈值操作\n",
    "THRESH_BINARY 超过阈值的部分取最大值，否则就是0\n",
    "THRESH)BINARY_INV 这个就是把THRESH_BINARY 的结果反过来\n",
    "THRESH_TRUNC 大于阈值的部分设为阈值，否则不变\n",
    "THRESH_TOZERO 大于阈值部分不变，否则设为0\n",
    "THRESH_TOZERO_INV 就是上边的TOZERO的反转\n",
    "\"\"\"\n",
    "ret,thresh1=cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2=cv2.threshold(img,100,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3=cv2.threshold(img,100,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4=cv2.threshold(img,100,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5=cv2.threshold(img,100,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['original','binary','binary_inv','trunc','tozero','tezero_inv']\n",
    "images = [img_org,thresh1,thresh2,thresh3,thresh4,thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray') # 在一个窗口显示多个图像\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自适应阈值\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "#中值滤波\n",
    "img = cv2.medianBlur(img,5)\n",
    "\n",
    "\n",
    "re,th1=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "#11 为block size,2w为c值\n",
    "th2=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "th3=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "titles=['Original Image','Global Thresholding(v=127)','Adaptive Mean Thresholding','Adaptive Gaussian Thresholding']\n",
    "images=[img,th1,th2,th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otsu's 二值化\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "\n",
    "#globle thresholding \n",
    "ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#Otsu's thresholding \n",
    "ret1,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding ater Gaussian filtering \n",
    "#(5,5)为高斯核的大小，0为标准差\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "# 阈值一定要设为0\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "#plot all the image and their histograms\n",
    "images = [img,0,th1,img,0,th2,blur,0,th3]\n",
    "titles=['Original Noisy Image','Histogram','Global Thresholding(v=127)','Original Noisy Image','Histogram',\"Otsu's Thresholding\",'Gasussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "\n",
    "# 这里使用了pyplot中画直方图的方法，plt.hist,要注意的是它的参数是一维数组\n",
    "# 所以这里使用了(numpy)ravel 方法，将多维数组转换成一维，也可以使用flatten方法\n",
    "# ndarray.flat 1-D iterator over an array.\n",
    "# ndarray.flatten 1-D array copy of the elements of an array in row-major order.\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]),plt.xticks([]),plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]),plt.xticks([]),plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]),plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#腐蚀 膨胀 开运算（先腐蚀再膨胀,去除噪声）\n",
    "# 闭运算 先膨胀再腐蚀，填充前景物体上的小洞\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "dilation = cv2.dilate(img,kernel,iterations =1)\n",
    "opening = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)\n",
    "closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)\n",
    "plt.subplot(2,3,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,3,2),plt.imshow(erosion,cmap ='gray')\n",
    "plt.title('erosion'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,3,3),plt.imshow(dilation,cmap = 'gray')\n",
    "plt.title('dilation'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,3,4),plt.imshow(opening,cmap = 'gray')\n",
    "plt.title('opening'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,3,5),plt.imshow(closing,cmap = 'gray')\n",
    "plt.title('closing'),plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img=cv2.imread(\"\",0)\n",
    "\n",
    "#cv2.CV_64F输出图像的深度（数据类型），可以使用-1，与原图像保持一致np.uint8\n",
    "laplacian=cv2.Laplacian(img,cv2.CV_64F)\n",
    "#参数1，0为只在x方向求一阶导数，最大可以求2阶导数\n",
    "sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "#参数1，0为只在y方向求一阶导数，最大可以求2阶导数\n",
    "sobely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian,cmap ='gray')\n",
    "plt.title('Laplacian'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel Y'),plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边缘检测\n",
    "%matplotlib notebook\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "img=cv2.imread(\"\",0)\n",
    "edges =cv2.Canny(img,60,110)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap='gray')\n",
    "plt.title('Original Image'),plt.xticks([]),plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'),plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像拼接\n",
    "import cv2\n",
    "import numpy as np,sys\n",
    "\n",
    "A = cv2.imread('')\n",
    "B = cv2.imread('')\n",
    "\n",
    "#generate Gaussian pyramid for A \n",
    "G = A.copy()\n",
    "gpA=[G]\n",
    "for i in range(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpA.append(G)\n",
    "\n",
    "# generate Laplacian pyramid for A \n",
    "lpA=[gpA[5]]\n",
    "for i in range(5,0,-1):\n",
    "    GE = cv2.pyrUp(gpA[i])\n",
    "    L = cv2.subtract(gpA[i-1],GE)\n",
    "    lpA.append(L)\n",
    "\n",
    "#generate Laplacian Pyramid for B\n",
    "lpB = [gpB[5]]\n",
    "for i in range (5,0,-1):\n",
    "    GE = cv2.pyrUp(gpB[i])\n",
    "    L = cv2.substract(gpB[i-1],GE)\n",
    "    lpB.append(L)\n",
    "\n",
    "#Now ad left and right halves of images in each level\n",
    "#numpy.hstack(tup)\n",
    "#Take a sequence of arrays and stack them horiziontally\n",
    "#to make a single array\n",
    "LS = []\n",
    "for la,lb in zip(lpA,lpB):\n",
    "    rows ,cols,dpt = la.shape\n",
    "    ls = np.hstack((la[:,0:cols/2],lb[:,clos/2:])) #两个图像的矩阵的左半部分和右半部分拼接到一起\n",
    "    LS.append(ls)\n",
    "\n",
    "# now reconstruct\n",
    "ls_ = LS[0] #高斯金字塔的最小图片\n",
    "for i in range(1,6): #第一次循环的图像为高斯金字塔的最小图片，依次通过拉普拉斯变换恢复到最大图像\n",
    "    ls_=cv2.pyrUp(ls_)\n",
    "    ls_=cv2.add(ls_,LS[i]) #采用金字塔拼接方法的图像\n",
    "\n",
    "#image with direct connecting each half\n",
    "real = np.hstack((A[:,:cols/2],B[:,cols/2:])) #直接的拼接\n",
    "\n",
    "cv2.imwrite('Pyramind_blending2.jpg',ls_)\n",
    "cv2.imwrite('Direct_blending.jpg',real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多对象的模板匹配\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_rgb = cv2.imread('')\n",
    "img_gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread('',0)\n",
    "w,h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.8\n",
    "\n",
    "# umpy.where(condition[,x,y])\n",
    "#Return elements ,either from x or y ,depengding on condition\n",
    "#If only condition is given,return condition,nonzero()\n",
    "loc = np.where(res>=threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb,pt,(pt[0]+w,pt[1]+h),(0,0,255),2)\n",
    "\n",
    "cv2.imwrite('res2.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#霍夫变换直线检测\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "img = cv2.imread(\"\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,10,150)\n",
    "minLineLength = 1000\n",
    "maxLineGap = 10\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,200,minLineLength,maxLineGap)\n",
    "line1 = lines[:,0,:]\n",
    "for x1,y1,x2,y2 in line1[:]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    \n",
    "cv2.imshow(\"edges\",edges)\n",
    "cv2.namedWindow('lines',0)\n",
    "cv2.imshow(\"lines\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轮廓检索\n",
    "import cv2 as cv\n",
    "#1 读取图片\n",
    "def read_rgb_img(img_name):\n",
    "    rgb_img=cv.imread(img_name,cv.IMREAD_COLOR)\n",
    "    cv.imshow(\"rgb img\",rgb_img)\n",
    "    return rgb_img\n",
    "\n",
    "#2 将图片转成一张灰色图片\n",
    "def convert_rgb2gray(img):\n",
    "    gray_img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    return gray_img\n",
    "\n",
    "#3 对图片进行二值化处理\n",
    "def convert_gray2binary(img):\n",
    "    _, binary_img = cv.threshold(img,0,255,cv.THRESH_BINARY_INV|cv.THRESH_OTSU)\n",
    "    return binary_img\n",
    "\n",
    "#4 使用 findContours查找轮廓\n",
    "def getContours(img):\n",
    "    _, contours,hierarchy = cv.findContours(img,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "    print(contours,hierarchy)\n",
    "    return contours\n",
    "\n",
    "#5 对轮廓进行处理\n",
    "def draw_contours(img,contours):\n",
    "    index = -1\n",
    "    thickness =2\n",
    "    color = (255,125,125)\n",
    "    imgg = cv.drawContours(img,contours,index,color,thickness)\n",
    "    cv.namedWindow('draw contours',0)\n",
    "    cv.imshow('draw contours',imgg)\n",
    "    for i,c in enumerate(contours):\n",
    "        circle = cv.minEnclosingCircle(c)\n",
    "        ((x,y),radius)=circle\n",
    "        cv.circle(imgg,(int(x),int(y)),int(radius),(0,0,255),2)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    img_name = \"\"\n",
    "    rgb_img = read_rgb_img(img_name)\n",
    "    gray_img = convert_rgb2gray(rgb_img)\n",
    "    binary_image=convert_gray2binary(gray_img)\n",
    "    contours = getContours(binary_image)\n",
    "    draw_contours(rgb_img,contours)\n",
    "    \n",
    "    cv.namedWindow('draw_contours_circle',0)\n",
    "    cv.imshow('draw_contours_circle',rgb_img)\n",
    "    \n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 霍夫圆环检测\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"\",0)\n",
    "img=cv2.medianBlur(img,5)\n",
    "cimg=cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,20,param1=50,param2=130,minRadius=0,maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    #draw the outer circle\n",
    "    cv2.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    #draw the center of the circle\n",
    "    cv2.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "cv2.imshow('detected circles',cimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分水岭算法图像分割\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def watershed_demo(image):\n",
    "    print(image.shape)\n",
    "    blurred = cv.pyrMeanShiftFiltering(image,10,100)\n",
    "    gray = cv.cvtColor(blurred,cv.COLOR_BGR2GRAY)\n",
    "    ret,binary=cv.threshold(gray,0,255,cv.THRESH_BINARY|cv.THRESH_OTSU)\n",
    "    cv.imshow(\"binary\",binary)\n",
    "    \n",
    "    #morphology operation\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
    "    opening = cv.morphologyEx(binary,cv.MORPH_OPEN,kernel=kernel,iterations=2)\n",
    "    sure_bg=cv.dilate(opening,kernel,iterations=3)\n",
    "    cv.imshow(\"morphology operation\",sure_bg)\n",
    "    # fingding sure foreground area\n",
    "    # 距离变换的基本含义是计算一个图像中非零像素点到最近的零像素点的距离\n",
    "    # 也就是到零像素点的最近距离\n",
    "    # 最常见的距离变换算法就是通过连续的腐蚀操作来实现，腐蚀操作的停止条件就是所有的前景像素都被被完全腐蚀\n",
    "    #这样根据腐蚀的先后顺序，我们就得到各个前景像素点到前景中心像素点的距离\n",
    "    #根据各个像素点的距离值，设置为不同的灰度值，这样就完成了二值图像的距离变换\n",
    "    #cv.distanceTransform(src,distanceType,maskSize)\n",
    "    #第二个参数0，1，2分别表示CV_DIST_L1,CV_DIST_L2,CV_DIST_C\n",
    "    dist_transform = cv.distanceTransform(opening,1,5)\n",
    "    ret,sure_fg=cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "    \n",
    "    #finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    ret,markers1=cv.connectedComponents(sure_fg)\n",
    "    print(ret)\n",
    "    \n",
    "    #watershed transform\n",
    "    markers = markers1+1\n",
    "    markers[unknown==255] = 0\n",
    "    markers3 = cv.watershed(image,markers=markers)\n",
    "    image[markers == -1]=[255,0,0]\n",
    "    cv.imshow(\"result\",image)\n",
    "\n",
    "    \n",
    "def main():\n",
    "    src=cv.imread(r\"\")\n",
    "    cv.imshow(\"demo\",src)\n",
    "    watershed_demo(src)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "if __name__== '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于梯度的分水岭图像分割\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import morphology,color,data,filters\n",
    "import cv2\n",
    "\n",
    "\n",
    "#image = color,rgb2gray(data.camara())\n",
    "image = cv2.imread(\"\",0)\n",
    "denoised = filters.rank.median(image,morphology.disk(2))#过滤噪声\n",
    "\n",
    "#将梯度值低于10的作为开始标记点\n",
    "markers = filters.rank.gradient(denoised,morphology.disk(5))<10\n",
    "markers = ndi.label(markers)[0]\n",
    "\n",
    "gradient = filters.rank.gradient(denoised,morphology.disk(2)) #计算梯度\n",
    "labels = morphology.watershed(gradient,markers,mask=image) # 基于梯度的分水岭算法\n",
    "\n",
    "fig,axes = plt.subplots(nrows=2,ncols=2,figsize=(6,6))\n",
    "axes =axes.ravel()\n",
    "ax0,ax1,ax2,ax3 = axes\n",
    "\n",
    "ax0.imshow(image,cmap=plt.cm.gray,interpolation='nearest')\n",
    "ax0.set_title(\"Original\")\n",
    "ax1.imshow(gradient,cmap=plt.cm.Spectral,interpolation='nearest')\n",
    "ax1.set_title(\"Gradient\")\n",
    "ax2.imshow(markers,cmap=plt.cm.Spectral,interpolation='nearest')\n",
    "ax2.set_title(\"Markers\")\n",
    "ax3.imshow(labels,cmap=plt.cm.Spectral,interpolation='nearest')\n",
    "ax3.set_title(\"Segmented\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GrabCut算法进行交互式前景提取\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def grabut(imgpath,rect,iterCount):\n",
    "    img= cv2.imread(imgpath)\n",
    "    \n",
    "    # 创建一个与所加载图像同形状的Mask\n",
    "    mask = np.zeros(img.shape[:2],np.uint8)\n",
    "    \n",
    "    # 算法内部使用的数组，必须创建两个np.float64类型的0数组，大小是（1，65）\n",
    "    \n",
    "    bgdModel= np.zeros((1,65),np.float64)\n",
    "    fgdModel= np.zeros((1,65),np.float64)\n",
    "    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,iterCount,cv2.GC_INIT_WITH_RECT)\n",
    "    # 掩模已经变为包含0-3之间的值，值为0和2转换为0，值为1和3转为1，并将结果存在mask2中\n",
    "    mask2=np.where((mask == 2)|(mask == 0),0,1).astype('uint8')\n",
    "    img = img*mask2[:,:,np.newaxis]\n",
    "    plt.subplot(121),plt.imshow(cv2.cvtColor(cv2.imread(imgpath),cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"original\"),plt.xticks([]),plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"grabcut\"),plt.xticks([]),plt.yticks([])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    imgpath =\"\"\n",
    "    # 人工前景的矩形区域（rect.x,rect.y,rect.width,rect.height）\n",
    "    rect=(0,0,10,100)\n",
    "    grabut(imgpath,rect,5)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#OpenCV GrabCut算法 物体分割(python语言)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "imgpath = ''\n",
    "img = cv2.imread(imgpath)\n",
    " \n",
    "# 预先绘制图片\n",
    "fig = plt.figure()\n",
    "plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(122), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    " \n",
    "def OnClick(event):\n",
    "    # 获取当鼠标\"按下\"的时候，鼠标的位置\n",
    "    global Coords1x, Coords1y\n",
    "    if event.button == 1:\n",
    "        Coords1x = int(event.xdata)\n",
    "        Coords1y = int(event.ydata)\n",
    "        print(\"1x1y\" + str(Coords1x) + str(Coords1y))\n",
    " \n",
    " \n",
    "def OnMouseMotion(event):\n",
    "    # 获取当鼠标\"移动\"的时候，鼠标的位置\n",
    "    global Coords2x, Coords2y\n",
    "    if event.button == 1:\n",
    "        Coords2x = int(event.xdata)\n",
    "        Coords2y = int(event.ydata)\n",
    "        print(\"2x2y\" + str(Coords2x) + str(Coords2y))\n",
    "        \n",
    "def OnMouseRelease(event):\n",
    "    if event.button == 1:\n",
    "        fig = plt.gca()\n",
    "        img = cv2.imread(imgpath)\n",
    "        # 创建一个与所加载图像同形状的Mask\n",
    "        mask = np.zeros(img.shape[:2], np.uint8)\n",
    " \n",
    "        # 算法内部使用的数组,你必须创建两个np.float64 类型的0数组,大小是(1, 65)\n",
    "        bgdModel = np.zeros((1, 65), np.float64)\n",
    "        fgdModel = np.zeros((1, 65), np.float64)\n",
    " \n",
    "        # 计算人工前景的矩形区域(rect.x,rect.y,rect.width,rect.height)\n",
    "        rect = (Coords1x, Coords1y, Coords2x - Coords1x, Coords2y - Coords1y)\n",
    "        print(rect)\n",
    "        iterCount = 5\n",
    "        cv2.grabCut(img, mask, rect, bgdModel, fgdModel, iterCount, cv2.GC_INIT_WITH_RECT)\n",
    " \n",
    "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "        img = img * mask2[:, :, np.newaxis]\n",
    "        plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.subplot(122), plt.imshow(\n",
    "            cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2RGB))\n",
    "        fig.figure.canvas.draw()\n",
    " \n",
    " \n",
    "# 连接鼠标点击事件\n",
    "fig.canvas.mpl_connect('button_press_event', OnClick)\n",
    "# 连接鼠标移动事件\n",
    "fig.canvas.mpl_connect('motion_notify_event', OnMouseMotion)\n",
    "fig.canvas.mpl_connect('button_release_event', OnMouseRelease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",module=\"matplotlib\")\n",
    "\n",
    "imgpath = ''\n",
    "img = cv2.imread(imgpath)\n",
    "\n",
    "Coords1x,Coords1y='NA','NA'\n",
    "Coords2x,Coords2y='NA','NA'\n",
    "\n",
    "def OnClick(event):\n",
    "    # 获取当鼠标\"按下\"的时候，鼠标的位置\n",
    "    global Coords1x, Coords1y\n",
    "    if event.button == 1:\n",
    "        try:\n",
    "            Coords1x = int(event.xdata)\n",
    "            Coords1y = int(event.ydata)\n",
    "        except:\n",
    "            Coords1x = event.xdata\n",
    "            Coords1y = event.ydata\n",
    "        print(\"1x1y\" + str(Coords1x) + str(Coords1y))\n",
    "\n",
    "\n",
    "def OnMouseMotion(event):\n",
    "    # 获取当鼠标\"移动\"的时候，鼠标的位置\n",
    "    global Coords2x, Coords2y\n",
    "    if event.button == 3:\n",
    "        try:\n",
    "\n",
    "            Coords2x = int(event.xdata)\n",
    "            Coords2y = int(event.ydata)\n",
    "        except:\n",
    "            Coords2x = event.xdata\n",
    "            Coords2y = event.ydata\n",
    "        print(\"2x2y\" + str(Coords2x) + str(Coords2y))\n",
    "\n",
    "\n",
    "def OnMouseRelease(event):\n",
    "    if event.button == 2:\n",
    "        fig = plt.gca()\n",
    "        img = cv2.imread(imgpath)\n",
    "        # 创建一个与所加载图像同形状的Mask\n",
    "        mask = np.zeros(img.shape[:2], np.uint8)\n",
    "        # 算法内部使用的数组,你必须创建两个np.float64 类型的0数组,大小是(1, 65)\n",
    "        bgdModel = np.zeros((1, 65), np.float64)\n",
    "        fgdModel = np.zeros((1, 65), np.float64)\n",
    "        # 计算人工前景的矩形区域(rect.x,rect.y,rect.width,rect.height)\n",
    "        if(Coords2x-Coords1x)>0 and (Coords2y-Coords1y)>0:\n",
    "            try:\n",
    "                rect = (Coords1x, Coords1y, Coords2x-Coords1x, Coords2y-Coords1y)\n",
    "                print('#### 分割区域',rect)\n",
    "                print(\"#### 等会儿 有点慢...\")\n",
    "                iterCount = 5\n",
    "                cv2.grabCut(img, mask, rect, bgdModel, fgdModel, iterCount, cv2.GC_INIT_WITH_RECT)\n",
    "                mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "                img = img * mask2[:, :, np.newaxis]\n",
    "                plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                plt.subplot(122), plt.imshow(cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2RGB))\n",
    "                fig.figure.canvas.draw()\n",
    "                print('May the force be with me!')\n",
    "            except:\n",
    "                print('#### 先左键 后右键')\n",
    "        else:\n",
    "            print('#### 左下角坐标值必须大于右上角坐标')\n",
    "\n",
    "\n",
    "# 预先绘制图片\n",
    "fig = plt.figure()\n",
    "plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(122), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.colorbar()\n",
    "\n",
    "# 鼠标左键，选取分割区域（长方形）的左上角点\n",
    "fig.canvas.mpl_connect('button_press_event', OnClick)\n",
    "# 鼠标右键，选取分割区域（长方形）的右下角点\n",
    "fig.canvas.mpl_connect('button_press_event', OnMouseMotion)\n",
    "# 鼠标中键，在所选区域执行分割操作\n",
    "fig.canvas.mpl_connect('button_press_event', OnMouseRelease)\n",
    "plt.show()\n",
    "\n",
    "# 连接鼠标点击事件\n",
    "#fig.canvas.mpl_connect('button_press_event', OnClick)\n",
    "# 连接鼠标移动事件\n",
    "#fig.canvas.mpl_connect('motion_notify_event', OnMouseMotion)\n",
    "#fig.canvas.mpl_connect('button_release_event', OnMouseRelease)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#角点检测\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "filename =''\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray=np.float32(gray)\n",
    "\n",
    "#输入图像必须是float32,最后一个参数在0.04到0.05之间\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners ,not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "#threshold for an optimal value, it may vary depengding on the image\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "if cv2.waitKey(0) & 0xff ==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#亚像素级精确度的角点\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "filename = \"\"\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#find harris corners\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "dst = cv2.dilate(dst,None)\n",
    "ret,dst=cv2.threshold(dst,0.01*dst.max(),255,0)\n",
    "dst = np.uint8(dst)\n",
    "\n",
    "#find centroids\n",
    "# connectedCompoentsWithStats(InputArray image ,OutputArray labels,OutpitArray status,)\n",
    "#OutputArray centroids, int connectivity = 8 ,int ltype = CV_32S)\n",
    "ret,labels,stats,centroids=cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "#define the criteria to stop and refine the corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER,100,0.001)\n",
    "\n",
    "corners = cv2.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "#Now draw them\n",
    "res = np.hstack((centroids,corners))\n",
    "#np.int0可以用来省略小数点后面的数字（非四舍五入）\n",
    "res = np.int0(res)\n",
    "img[res[:,1],res[:,0]]=[0,0,255]\n",
    "img[res[:,3],res[:,2]] = [0,255,0]\n",
    "\n",
    "cv2.imshow('subpixl5.png',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用掩模统计图像某个局部区域的直方图\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "\n",
    "# create a mask\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "mask[100:300,100:300] = 255\n",
    "masked_img = cv2.bitwise_and(img,img,mask = mask)\n",
    "\n",
    "# Caculate histogram with mask and without mask\n",
    "# Check third argument for mask\n",
    "\n",
    "hist_full = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "hist_mask = cv2.calcHist([img],[0],mask,[256],[0,256])\n",
    "\n",
    "plt.subplot(221),plt.imshow(img,'gray')\n",
    "plt.subplot(222),plt.imshow(mask,'gray')\n",
    "plt.subplot(223),plt.imshow(masked_img,'gray')\n",
    "plt.subplot(224),plt.plot(hist_full),plt.plot(hist_mask)\n",
    "plt.xlim([0,256])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直方图均衡化\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "\n",
    "# flatten() 将数组变成一维\n",
    "hist,bins=np.histogram(img.flatten(),256,[0,256])\n",
    "# 计算累积分布图\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf*hist.max()/cdf.max()\n",
    "\n",
    "# 构建Numpy掩模数组，cdf为原数组，当数组元素为0时，掩盖\n",
    "cdf_m = np.ma.masked_equal(cdf,0)\n",
    "cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max() - cdf_m.min())\n",
    "#对被掩盖的元素赋值，这里赋值为0\n",
    "cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "img2 = cdf[img]\n",
    "\n",
    "cv2.namedWindow('img2',2)\n",
    "cv2.imshow('img2',img2)\n",
    "if cv2.waitKey(0) & 0xff ==27:\n",
    "    cv2.destroyAllWindows()\n",
    "#plt.plot(cdf_normalized,color = 'b')\n",
    "#plt.hist(img2.flatten(),256,[0,256],color = 'r')\n",
    "#plt.xlim([0,256])\n",
    "#plt.legend(('cdf','histogram'),loc = 'upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D直方图\n",
    "%matplotlib notebook\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('')\n",
    "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "hist = cv2.calcHist([hsv],[0,1],None,[180,256],[0,180,0,256])\n",
    "\n",
    "plt.imshow(hist,interpolation = 'nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 傅里叶变换\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#simple aceraging filter without scaling parameter\n",
    "mean_filter = np.ones((3,3))\n",
    "\n",
    "# creating a guassian filter\n",
    "x = cv2.getGaussianKernel(5,10)\n",
    "#x.T 为矩阵转置\n",
    "gaussian = x*x.T\n",
    "\n",
    "# diffrent edge detecting filters\n",
    "# scharr in x-direction\n",
    "scharr = np.array([[-3,0,3],[-10,0,10],[-3,0,3]])\n",
    "# sobel in x dicrection\n",
    "sobel_x = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "#sobel in y dicrection\n",
    "sobel_y = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
    "# laplacian\n",
    "laplacian=np.array([[0,1,0],[1,-4,1],[0,1,0]])\n",
    "\n",
    "filters = [mean_filter,gaussian,laplacian,sobel_x,sobel_y,scharr]\n",
    "filter_name = ['mean_filters','gaussian','laplacian','sobel_x','sobel_y','scharr_x']\n",
    "\n",
    "fft_filters = [np.fft.fft2(x) for x in filters]\n",
    "fft_shift = [np.fft.fftshift(y) for y in fft_filters]\n",
    "mag_spectrum = [np.log(np.abs(z)+1) for z in fft_shift]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(mag_spectrum[i],cmap='gray')\n",
    "    plt.title(filter_name[i]),plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shi-Tomasi 角点检测&适合于跟踪的图像特征\n",
    "#试着找出25个最佳角点\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray,30,0.01,10)\n",
    "# 返回的结果时[[311.,250.]]两层括号的数组\n",
    "corners = np.int0(corners)\n",
    "\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),3,255,-1)\n",
    "\n",
    "plt.imshow(img),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT 算法\n",
    "import numpy as np\n",
    "import  cv2 as  cv\n",
    "img = cv.imread(\"\")\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "sift = cv.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "\n",
    "cv.imshow(\" SIFT\",img)\n",
    "cv.imwrite('sift_keypoints.jpg',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重置一张图片的大小类型，使其与另一张图片大小类型相同\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('')\n",
    "\n",
    "gakki101 = cv2.imread('gakki101.jpg')\n",
    "gakki102 = cv2.imread('gakki102.jpg')\n",
    "\n",
    "rows,cols = gakki102.shape[:2] #获取sky的高度、宽度\n",
    "#print(gakki102.shape[:2])\n",
    "#print(bgakki101,shape[:2])\n",
    "gakki101_dst = cv2.resize(gakki101,(cols,rows),interpolation=cv2.INTER_CUBIC) #放大图像\n",
    "add_img = cv2.addWeighted(gakki101_dst,0.6,gakki102,0.4,0) #图像融合\n",
    "\n",
    "cv2.imwrite('sift_keypoints.jpg',gakki101_dst)\n",
    "#显示图片\n",
    "titles = ['gakki101','gakki102','add_img']\n",
    "imgs = [gakki101,gakki102,add_img]\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    imgs[i] = cv2.cvtColor(imgs[i],cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(imgs[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于BFmatcher的SIFT实现\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imgname1 = ''\n",
    "imgname2 = ''\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "img1 = cv2.imread(imgname1)\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # 灰度处理图像\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)  # des是描述子\n",
    "\n",
    "img2 = cv2.imread(imgname2)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)  # 灰度处理图像\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)  # des是描述子\n",
    "\n",
    "hmerge = np.hstack((gray1, gray2))  # 水平拼接\n",
    "cv2.imshow(\"gray\", hmerge)  # 拼接显示为gray\n",
    "cv2.waitKey(0)\n",
    "\n",
    "img3 = cv2.drawKeypoints(img1, kp1, img1, color=(255, 0, 255))  # 画出特征点，并显示为红色圆圈\n",
    "img4 = cv2.drawKeypoints(img2, kp2, img2, color=(255, 0, 255))  # 画出特征点，并显示为红色圆圈\n",
    "hmerge = np.hstack((img3, img4))  # 水平拼接\n",
    "cv2.imshow(\"point\", hmerge)  # 拼接显示为gray\n",
    "cv2.waitKey(0)\n",
    "# BFmatchaer解决匹配\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "# 调整ratio\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "img5 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)\n",
    "cv2.imshow(\"BFmatch\",img5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用FAST作为特征描述的关键代码和提取图像显示：\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"\",0)\n",
    "\n",
    "fast=cv2.FastFeatureDetector_create() #获取FAST角点探测器\n",
    "kp=fast.detect(img,None) #描述符\n",
    "img = cv2.drawKeypoints(img,kp,img,color=(255,255,0)) # 画到Imgs上面\n",
    "print(\"Threshold:\",fast.getThreshold())#输出阈值\n",
    "print(\"normaxSuppression:\",fast.getNonmaxSuppression())#是否使用非极大值抑制\n",
    "print(\"Total Keypoints with nonmaxSuppression\",len(kp)) #特征点个数\n",
    "cv2.imshow('fast',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于FlannBasedMatcher的SURF实现\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imgname1 = ''\n",
    "imgname2 = ''\n",
    "\n",
    "surf = cv2.SURF_create()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params=dict(algorithm = FLANN_INDEX_KDTREE,trees = 5)\n",
    "search_params=dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "\n",
    "img1 = cv2.imread(imgname1)\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # 灰度处理图像\n",
    "kp1,des1 = surf.detectAndCompute(img1, None)  # des是描述子\n",
    "\n",
    "img2 = cv2.imread(imgname2)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)  # 灰度处理图像\n",
    "kp2,des2 = surf.detectAndCompute(img2, None)  # des是描述子\n",
    "\n",
    "hmerge = np.hstack((gray1, gray2))  # 水平拼接\n",
    "cv2.imshow(\"gray\", hmerge)  # 拼接显示为gray\n",
    "cv2.waitKey(0)\n",
    "\n",
    "img3 = cv2.drawKeypoints(img1, kp1, img1, color=(255, 0, 255))  # 画出特征点，并显示为红色圆圈\n",
    "img4 = cv2.drawKeypoints(img2, kp2, img2, color=(255, 0, 255))  # 画出特征点，并显示为红色圆圈\n",
    "\n",
    "hmerge = np.hstack((img3, img4))  # 水平拼接\n",
    "cv2.imshow(\"point\", hmerge)  # 拼接显示为gray\n",
    "cv2.waitKey(0)\n",
    "\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "# 调整ratio\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "img5 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)\n",
    "cv2.imshow(\"SURF\",img5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于BFmatcher的ORB实现\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imgname1 = ''\n",
    "imgname2 = ''\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "img1 = cv2.imread(imgname1)\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # 灰度处理图像\n",
    "kp1,des1 = orb.detectAndCompute(img1, None)  # des是描述子\n",
    "\n",
    "img2 = cv2.imread(imgname2)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)  # 灰度处理图像\n",
    "kp2,des2 = orb.detectAndCompute(img2, None)  # des是描述子\n",
    "\n",
    "hmerge = np.hstack((gray1, gray2))  # 水平拼接\n",
    "cv2.imshow(\"gray\", hmerge)  # 拼接显示为gray\n",
    "cv2.waitKey(0)\n",
    "\n",
    "img3 = cv2.drawKeypoints(img1, kp1, img1, color=(255, 0, 255))  # 画出特征点，并显示为红色圆圈\n",
    "img4 = cv2.drawKeypoints(img2, kp2, img2, color=(255, 0, 255))  # 画出特征点，并显示为红色圆圈\n",
    "hmerge = np.hstack((img3, img4))  # 水平拼接\n",
    "cv2.imshow(\"point\", hmerge)  # 拼接显示为gray\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# BFmatchaer解决匹配\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "# 调整ratio\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "img5 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)\n",
    "cv2.imshow(\"orb\",img5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "#人脸识别类 - 使用face_recognition模块\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "path = \"img/face_recognition\"  # 模型数据图片目录\n",
    "cap = cv2.VideoCapture(0)\n",
    "total_image_name = []\n",
    "total_face_encoding = []\n",
    "for fn in os.listdir(path):  #fn 表示的是文件名q\n",
    "    print(path + \"/\" + fn)\n",
    "    total_face_encoding.append(\n",
    "        face_recognition.face_encodings(\n",
    "            face_recognition.load_image_file(path + \"/\" + fn))[0])\n",
    "    fn = fn[:(len(fn) - 4)]  #截取图片名（这里应该把images文件中的图片名命名为为人物名）\n",
    "    total_image_name.append(fn)  #图片名字列表\n",
    "while (1):\n",
    "    ret, frame = cap.read()\n",
    "    # 发现在视频帧所有的脸和face_enqcodings\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "    # 在这个视频帧中循环遍历每个人脸\n",
    "    for (top, right, bottom, left), face_encoding in zip(\n",
    "            face_locations, face_encodings):\n",
    "        # 看看面部是否与已知人脸相匹配。\n",
    "        for i, v in enumerate(total_face_encoding):\n",
    "            match = face_recognition.compare_faces(\n",
    "                [v], face_encoding, tolerance=0.5)\n",
    "            name = \"Unknown\"\n",
    "            if match[0]:\n",
    "                name = total_image_name[i]\n",
    "                break\n",
    "        # 画出一个框，框住脸\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        # 画出一个带名字的标签，放在框下\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255),\n",
    "                      cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0,\n",
    "                    (255, 255, 255), 1)\n",
    "    # 显示结果图像\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image=cv2.imread('')\n",
    "HSV=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "def getpos(event,x,y,flags,param):\n",
    "    if event==cv2.EVENT_LBUTTONDOWN: #定义一个鼠标左键按下去的事件\n",
    "        print(HSV[y,x])\n",
    "        \n",
    "cv2.namedWindow(\"imageHSV\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"imageHSV\",HSV)\n",
    "cv2.namedWindow(\"image\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image',image)\n",
    "cv2.setMouseCallback(\"imageHSV\",getpos)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
